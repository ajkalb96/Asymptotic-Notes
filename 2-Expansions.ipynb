{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "init_printing(use_latex='mathjax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymptotic Expansions\n",
    "\n",
    "## Order notation\n",
    "\n",
    "Order notation is a way to compare the growth of one function to another in a particular limit $x\\to a$. The most famous example is Big O notation, where we say that $f(x) = O(g(x))$ as $x\\to a$ if $$\\limsup_{x\\to a}\\frac{|f(x)|}{|g(x)|} < \\infty.$$ The other term utilized in asymptotics is little o, where $f(x) = o(g(x))$ as $x\\to a$ if $$\\limsup_{x\\to a}\\frac{|f(x)|}{|g(x)|} = 0, g\\neq0.$$\n",
    "\n",
    "Other symbols are also commonly used to express these ideas, so we might say $f \\ll g$ if $f=o(g)$ or $f\\sim g$ if $f/g\\to1$. Computer scientists and programmers might also be familiar with big and little $\\omega$ s and $\\theta$ s, but that specificity is outside the scope of this work. And while the computer scientist often uses these notations in the limit as $n\\to\\infty$ in the context of algorithmic complexity and space, in asymptotics limits can be for variables like $x$ or parameters like $\\epsilon$, and often at limits of $0$ as well as $\\infty.$\n",
    "\n",
    "Sympy is nice in that it can handle big O notation fairly well, even with multiple variables, defaulting to a limit of 0. From their documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle O\\left(1; \\left( x, \\  y\\right)\\rightarrow \\left( 0, \\  0\\right)\\right)$"
      ],
      "text/plain": [
       "O(1; (x, y) → (0, 0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle O\\left(x y; \\left( x, \\  y\\right)\\rightarrow \\left( \\infty, \\  \\infty\\right)\\right)$"
      ],
      "text/plain": [
       "O(x⋅y; (x, y) → (∞, ∞))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle O\\left(1; \\left( x, \\  y\\right)\\rightarrow \\left( 0, \\  0\\right)\\right)$"
      ],
      "text/plain": [
       "O(1; (x, y) → (0, 0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = symbols('x y')\n",
    "display(O(1 + x*y))\n",
    "display(O(1 + x*y, (x, oo), (y, oo))) # oo is infty\n",
    "display(O(1 + x*y, (x, 0), (y, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansions\n",
    "\n",
    "We define an asymptotic sequence to be a sequence of gauge functions $\\{f_n\\}$ such that $f_{n+1}=o(f_n)$ at some limit. An asympotic expansion of $f$ is when we have a sequence of coefficients ${a_n}$ such that $$f(x)-\\sum_{n=0}^N\\phi_n = o(\\phi_N)$$ at the same limit, also denoted $f\\sim\\sum a_n\\phi_n$\n",
    "\n",
    "For a given sequence of gauge functions, we can compute the coefficients with the following formula: $$a_{N+1} = \\lim \\frac{f(x) - \\sum_{n=0}^N a_n\\phi_n(x)}{\\phi_{N+1}(x)}$$\n",
    "\n",
    "The following code shows such an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\log{\\left(\\sin{\\left(x \\right)} \\right)}$"
      ],
      "text/plain": [
       "log(sin(x))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{x^{6}}{2835} - \\frac{x^{4}}{180} - \\frac{x^{2}}{6} + \\log{\\left(x \\right)}$"
      ],
      "text/plain": [
       "    6     4     2         \n",
       "   x     x     x          \n",
       "- ──── - ─── - ── + log(x)\n",
       "  2835   180   6          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = log(sin(x))\n",
    "phi = [log(x), x**2, x**4, x**6]\n",
    "f_asymp = 0\n",
    "for p in phi:\n",
    "    a = limit((f-f_asymp)/p,x,0,'+')\n",
    "    f_asymp = f_asymp + a*p\n",
    "\n",
    "display(f,f_asymp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on Asymptotic Expansions\n",
    "\n",
    "- Addition and Scaling: No problems\n",
    "- Multiplication: could get messy with the wrong gauge functions, but nothing in principle\n",
    "- Term-by-term integration: Valid\n",
    "- Term-by-term differentiation: could break down with highly oscillatory terms, e.g. $\\sin(1/x)$\n",
    "\n",
    "Broadly speaking, pathologies of a function will not go away with an asymptotic expansion. \n",
    "\n",
    "### Asymptotic Power Series\n",
    "\n",
    "A Taylor series expansion is a valid asymptotic expansion.\n",
    "\n",
    "[Borel's Lemma](https://en.wikipedia.org/wiki/Borel's_lemma) can be used to show that any asymptotic power series is asymptotic to some $C^\\infty$ function.\n",
    "\n",
    "### Convergent versus Asymptotic Series\n",
    "\n",
    "Consider the series $S_N(x) = \\sum_{n=0}^N a_n\\phi_n(x).$ An asymptotic series is concerned with the behavior in some particular limit of $x$, where as convergence is concerned with the behavior in the limit $N\\to\\infty$.\n",
    "\n",
    "The following example takes the same function $\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-y^2} dy$ and constructs a convergent, asymptotic series as $x\\to0$ (the Taylor Series), and a divergent, asymptotic series as $x\\to\\infty.$\n",
    "\n",
    "Despite being covergent, the Taylor series does not do a great job at evaluating the function at $x=3$, whereas the four terms of the divergent series yields six digits of accuracy. That is not to say that more terms in the divergent series immediately leads to more accuracy; it tends to perform well up to a certain number of terms before the divergence takes over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.999977909503001$"
      ],
      "text/plain": [
       "0.999977909503001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{x^{7}}{21 \\sqrt{\\pi}} + \\frac{x^{5}}{5 \\sqrt{\\pi}} - \\frac{2 x^{3}}{3 \\sqrt{\\pi}} + \\frac{2 x}{\\sqrt{\\pi}}$"
      ],
      "text/plain": [
       "    7       5       3      \n",
       "   x       x     2⋅x    2⋅x\n",
       "- ───── + ──── - ──── + ───\n",
       "  21⋅√π   5⋅√π   3⋅√π   √π "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -38.1069764430542$"
      ],
      "text/plain": [
       "-38.1069764430542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1 - \\frac{e^{- x^{2}}}{\\sqrt{\\pi} x} + \\frac{e^{- x^{2}}}{2 \\sqrt{\\pi} x^{3}} - \\frac{3 e^{- x^{2}}}{4 \\sqrt{\\pi} x^{5}}$"
      ],
      "text/plain": [
       "       2       2          2 \n",
       "     -x      -x         -x  \n",
       "    ℯ       ℯ        3⋅ℯ    \n",
       "1 - ──── + ─────── - ───────\n",
       "    √π⋅x         3         5\n",
       "           2⋅√π⋅x    4⋅√π⋅x "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.999977865641434$"
      ],
      "text/plain": [
       "0.999977865641434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = 2/sqrt(pi) * integrate(exp(-y**2), (y,0,x))\n",
    "eval3 = lambda f: N(f.subs({x:3}).simplify())\n",
    "display(eval3(f))\n",
    "phi = [x,x**3,x**5,x**7]\n",
    "f_asymp = 0\n",
    "for p in phi:\n",
    "    a = limit((f-f_asymp)/p,x,0,'+')\n",
    "    f_asymp = f_asymp + a*p\n",
    "display(f_asymp,eval3(f_asymp))\n",
    "\n",
    "phi = [1,exp(-x**2)*x**-1,exp(-x**2)*x**-3,exp(-x**2)*x**-5]\n",
    "f_asymp = 0\n",
    "for p in phi:\n",
    "    a = limit((f-f_asymp)/p,x,oo)\n",
    "    f_asymp = f_asymp + a*p\n",
    "display(f_asymp,eval3(f_asymp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stokes Phenomenon\n",
    "\n",
    "If an asymptotic expansion is taking place over the complex numbers, then as $z$ approaches any essential singularity (often at $\\infty$), then the asymptotic expansion will often be depend on which 'slice' of the complex plane it approaches the singularity from. For example, our asymptotic expansion for $\\text{erf}$ has a leading coefficient of 1, if we performed it in the limit $x\\to-\\infty$ the lead coefficient would become -1 (you can try this), or zero as $x\\to \\pm i\\infty$ (sympy does not support this). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
